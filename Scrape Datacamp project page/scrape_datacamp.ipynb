{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Datacamp project page\n",
    "Every time I finished a [DataCamp project](https://www.datacamp.com/projects) I added it to my [DataCamp_projects repo](https://github.com/mrbarkis/DataCamp_projects). Unfortunately, I forgot to add descriptions and keywords, which annoys me to no end ; I remember using some technique in the projects but can't remember in which. Luckily, we can now use what DataCamp thought us; 1) we can scrape descriptions from the DataCamp projects page; 2) we can use NLP-techniques to determine the keywords for each project. \n",
    "\n",
    "## Plan:\n",
    "    1. Store relevant DataCamp and GitHub pages as local html-files\n",
    "    2. Find out which projects are listed on GitHub (my completed projects)\n",
    "    3. Find every project on DataCamp, and collect their descriptions.\n",
    "    4. Join the data from GitHub and DataCamp\n",
    "    5. Extract texts, functions, methods, attributes, imports from the notebooks\n",
    "        5.1. Find urls to the notebooks from GitHub\n",
    "        5.2. Define helper functions that can parse code, text, etc from the notebooks.\n",
    "        5.3. Download and parse all the notebooks\n",
    "    6. Analyze which words, and functions are most descriptive\n",
    "        6.1. Tokenize the imports and texts, which are still sentenses\n",
    "        6.2. Sort the tokens using the tf-idf, or term frequency–inverse document frequency, metric.\n",
    "    7. Exract long descriptions from DataCamp\n",
    "    8. Generate markdown description of each project.\n",
    "    \n",
    "If nothing works, you can load the backed up data\n",
    "```python\n",
    "#joined = pd.read_csv(\"./data/data_backup.csv\")\n",
    "joined = pd.read_csv(\"./data/raw_data_backup.csv\")\n",
    "```\n",
    "and start from section 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store relevant DataCamp and GitHub pages as local html-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an old file: ./localdata/datacamp_projects.html\n",
      "Using an old file: ./localdata/dc.json\n",
      "Using an old file: ./localdata/repo.html\n"
     ]
    }
   ],
   "source": [
    "# Urls to scrape:\n",
    "datacamp_url = \"https://www.datacamp.com/projects\" # Old, cannot be scraped any more\n",
    "dc_json_url = \"https://static.datacamp.com/page-data/projects/page-data.json\" # New page uses this json\n",
    "repo_url = \"https://github.com/mrbarkis/DataCamp_projects\"\n",
    "\n",
    "# Store the pages as local files (to avoid downloading projects multiple times)\n",
    "datacamp_file = \"./localdata/datacamp_projects.html\"\n",
    "repo_file = \"./localdata/repo.html\"\n",
    "dc_json_file = \"./localdata/dc.json\"\n",
    "\n",
    "# Force an update even if the file exists\n",
    "update_datacamp_data = False\n",
    "update_repo_data = False\n",
    "backup = True\n",
    "\n",
    "def downloadPage(url, save_as, overwrite=False, binary=False):\n",
    "    \"\"\"Download and save the page locally if it does not exist.\"\"\"\n",
    "\n",
    "    if path.exists(save_as) & ~overwrite:\n",
    "        print(\"Using an old file: \" + save_as)\n",
    "    else:\n",
    "        print(\"Downloading from: \" + url)\n",
    "        r = requests.get(url) \n",
    "        r.encoding = 'utf-8'\n",
    "        if binary:\n",
    "            flag = 'wb'\n",
    "            content = r.content\n",
    "        else:\n",
    "            flag = 'w'\n",
    "            content = r.text\n",
    "        print(\"Storing locally to: \" + save_as)\n",
    "        with open(save_as, flag) as file:\n",
    "            file.write(content)\n",
    "\n",
    "downloadPage(datacamp_url, datacamp_file, overwrite=update_datacamp_data)\n",
    "downloadPage(dc_json_url, dc_json_file, overwrite=update_datacamp_data)\n",
    "downloadPage(repo_url, repo_file, overwrite=update_repo_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find out which projects are listed on GitHub (my completed projects)\n",
    "On my [GitHub repo](https://github.com/mrbarkis/DataCamp_projects), the completed projects are listed as follows\n",
    "![folder links in github](img/repo.png \"GitHub repo\")\n",
    "Here, the folders are links that are defined with the following tags\n",
    "\n",
    "```html\n",
    "<a class=\"js-navigation-open link-gray-dark\" title=\"Introduction to DataCamp Projects\" id=\"81072776ec78e14d9ae418bc284e3ff2-26df00cc7b5540117f4a7a790b33cae72fe611a1\" href=\"/mrbarkis/DataCamp_projects/tree/master/Introduction%20to%20DataCamp%20Projects\">Introduction to DataCamp Projects</a>\n",
    "```\n",
    "\n",
    "We can use Beatifulsoup to find and process these tags. Let's also build a DataFrame that contains titles and hrefs for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Visual History of Nobel Prize Winners</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "2  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                     title language  \n",
       "0    A Network Analysis of Game of Thrones   python  \n",
       "1   A New Era of Data Analysis in Baseball   python  \n",
       "2  A Visual History of Nobel Prize Winners   python  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(repo_file, 'r') as html_file:\n",
    "    html_repo = BeautifulSoup(html_file)\n",
    "\n",
    "completed_projects = pd.DataFrame()\n",
    "\n",
    "for tag in html_repo.findAll(\"a\", {\"class\": \"js-navigation-open link-gray-dark\"}):\n",
    "    title = tag.text\n",
    "    link = tag.get('href')\n",
    "    if title not in [\"README.md\", \".gitignore\"]:\n",
    "        completed_projects = completed_projects.append(\n",
    "                                {\"title\": title.strip(),\n",
    "                                 \"repo_url\": \"https://github.com\" + link},\n",
    "                                ignore_index=True)\n",
    "        \n",
    "\n",
    "completed_projects[\"language\"] = \"python\" # For now, I have completed only Python projects\n",
    "completed_projects.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find every project on DataCamp, and collect their descriptions\n",
    "On the [DataCamp projects page](https://www.datacamp.com/projects), the projects are listed as follows\n",
    "\n",
    "![project wreppers](img/datacamp_projects.png \"GitHub repo\")\n",
    "\n",
    "In the past, each project has a wrapper tag that contains the following \n",
    "```html\n",
    "    <div class=\"dc-project-block-wrapper\">\n",
    "        <h5 class=\"dc-project-block__title\">Visualizing COVID-19</h5>\n",
    "        <small class=\"dc-project-block__description\">\n",
    "            Visualize the rise of COVID-19 cases globally withggplot2. \n",
    "        </small>\n",
    "        <p class=\"dc-project-block__author-name\">Richie Cotton</p>\n",
    "        <p class=\"dc-project-block__author-bio\">Curriculum Architect at DataCamp</p>\n",
    "        <img alt=\"R icon\" class=\"dc-project-block__technology\" src=\"___.svg\"/>\n",
    "        <a class=\"shim ds-snowplow-link-project-block\" href=\"/projects/870\"></a>\n",
    "    </div>\n",
    "```\n",
    "The commented code below, uses Beatifulsoup to find and process these tags. Unfortunately, the pages have changed, so it no longer works. Currently, the info is stored in a json file.\n",
    "\n",
    "\"https://static.datacamp.com/page-data/projects/page-data.json\"\n",
    "\n",
    ",which we can download and read easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(datacamp_file, 'r') as html_file:\n",
    "#    html = BeautifulSoup(html_file)\n",
    "#\n",
    "##print(\"### TYPICAL PROJECT WRAPPER LOOKS LIKE THIS ###\")\n",
    "##print(html.prettify())\n",
    "#\n",
    "#project = html.find(\"div\", {\"class\": \"dc-project-block-wrapper\"})\n",
    "#print(project.prettify())\n",
    "#\n",
    "#def scrape_info(project):\n",
    "#    \"\"\"Scrape relevant info from bs4 tag element, such as\n",
    "#    project = html.find(\"div\", {\"class\": \"dc-project-block-wrapper\"})\n",
    "#    \"\"\"\n",
    "#    language = project.find('img', {\"class\": \"dc-project-block__technology\"}).get('alt')[0]\n",
    "#    title = project.find('h5').text.strip()\n",
    "#    description = project.find('small').text.strip()\n",
    "#    author = project.find(\"p\", {\"class\": \"dc-project-block__author-name\"}).text.strip()\n",
    "#   bio = project.find(\"p\", {\"class\": \"dc-project-block__author-bio\"}).text.strip()\n",
    "#    url = (\"https://www.datacamp.com\"\n",
    "#                + project.find(\"a\", {\"class\": \"shim ds-snowplow-link-project-block\"}).get('href'))\n",
    "#     return {\"language\": language,\n",
    "#             \"title\": title,\n",
    "#             \"description\": description,\n",
    "#             \"datacamp_url\": url,\n",
    "#             \"author\": author,\n",
    "#             \"bio\": bio}\n",
    "\n",
    "\n",
    "# all_projects = pd.DataFrame()\n",
    "\n",
    "# for project in html.findAll(\"div\", {\"class\": \"dc-project-block-wrapper\"}):\n",
    "#     all_projects = all_projects.append(scrape_info(project), ignore_index=True)\n",
    "\n",
    "# #print(projects_df.info())\n",
    "# all_projects.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/33</td>\n",
       "      <td>If you've never done a DataCamp project, this ...</td>\n",
       "      <td>python</td>\n",
       "      <td>Introduction to DataCamp Projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/41</td>\n",
       "      <td>If you have never done a DataCamp project, thi...</td>\n",
       "      <td>r</td>\n",
       "      <td>Introduction to DataCamp Projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richie Cotton</td>\n",
       "      <td>Curriculum Architect at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/870</td>\n",
       "      <td>Visualize the rise of COVID-19 cases globally ...</td>\n",
       "      <td>r</td>\n",
       "      <td>Visualizing COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                                bio  \\\n",
       "0   Rasmus Bååth  Senior Data Scientist at King (Activision Bliz...   \n",
       "1   Rasmus Bååth  Senior Data Scientist at King (Activision Bliz...   \n",
       "2  Richie Cotton                   Curriculum Architect at DataCamp   \n",
       "\n",
       "                            datacamp_url  \\\n",
       "0   https://www.datacamp.com/projects/33   \n",
       "1   https://www.datacamp.com/projects/41   \n",
       "2  https://www.datacamp.com/projects/870   \n",
       "\n",
       "                                         description language  \\\n",
       "0  If you've never done a DataCamp project, this ...   python   \n",
       "1  If you have never done a DataCamp project, thi...        r   \n",
       "2  Visualize the rise of COVID-19 cases globally ...        r   \n",
       "\n",
       "                               title  \n",
       "0  Introduction to DataCamp Projects  \n",
       "1  Introduction to DataCamp Projects  \n",
       "2               Visualizing COVID-19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(dc_json_file, 'r') as file:\n",
    "       j = json.load(file)\n",
    "        \n",
    "# Explore the dictionary\n",
    "#print(j['result']['data'].keys())\n",
    "#print(j['result']['data']['allProject']['nodes'][0])\n",
    "\n",
    "all_projects = pd.DataFrame()\n",
    "for p in j['result']['data']['allProject']['nodes']: # p in projects\n",
    "    info = dict()\n",
    "    #p = j['result']['data']['allProject']['nodes']\n",
    "    select_as_is = {'title', 'description', 'language'}\n",
    "    info = {key: p[key] for key in p if key in select_as_is}\n",
    "    info[\"datacamp_url\"] = datacamp_url+ \"/\" + p[\"id\"].split('-')[-1]\n",
    "    info[\"author\"] = p[\"instructors\"][0][\"fullName\"]\n",
    "    info[\"bio\"] = p[\"instructors\"][0][\"marketingBiography\"]\n",
    "    all_projects = all_projects.append(info, ignore_index=True)\n",
    "\n",
    "all_projects.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join the data from GitHub and DataCamp\n",
    "We can now add info from \"all_projects\" to the \"completed_projects\" by \"left-joining\" them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Visual History of Nobel Prize Winners</td>\n",
       "      <td>python</td>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/441</td>\n",
       "      <td>Explore a dataset from Kaggle containing a cen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "2  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                     title language         author  \\\n",
       "0    A Network Analysis of Game of Thrones   python    Mridul Seth   \n",
       "1   A New Era of Data Analysis in Baseball   python  David Venturi   \n",
       "2  A Visual History of Nobel Prize Winners   python   Rasmus Bååth   \n",
       "\n",
       "                                                 bio  \\\n",
       "0                            Data science enthusiast   \n",
       "1                     Curriculum Manager at DataCamp   \n",
       "2  Senior Data Scientist at King (Activision Bliz...   \n",
       "\n",
       "                            datacamp_url  \\\n",
       "0   https://www.datacamp.com/projects/76   \n",
       "1  https://www.datacamp.com/projects/250   \n",
       "2  https://www.datacamp.com/projects/441   \n",
       "\n",
       "                                         description  \n",
       "0  Analyze the network of characters in Game of T...  \n",
       "1  Use MLB's Statcast data to compare New York Ya...  \n",
       "2  Explore a dataset from Kaggle containing a cen...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#completed_projects.join(all_projects, on=['title', 'language'], how='right')\n",
    "joined = pd.merge(completed_projects, all_projects,\n",
    "         left_on=['title', 'language'], right_on=['title', 'language'],\n",
    "         how='left')\n",
    "\n",
    "# There might be missing values if DataCamp has changed their project names\n",
    "missing = joined[joined.isna().any(axis=1)]\n",
    "#missing.title\n",
    "if len(missing) != 0:\n",
    "    print(\"Some info is missing!\")\n",
    "    missing.title\n",
    "else:\n",
    "    display(joined.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract texts, functions, methods, attributes, imports from the notebooks\n",
    "This is a bit more complicated step. We want to know what words and functions describe each project the most. The plan is to:\n",
    "    1. Find urls to the notebooks from GitHub.\n",
    "    2. Define helper functions that can parse code, text, etc from the notebooks.\n",
    "    3. Download and parse all the notebooks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Find urls to the notebooks from GitHub.\n",
    "At each \"repo_url\", the notebook.ipynb is shown as a link, for example\n",
    "```html\n",
    "<a class=\"js-navigation-open link-gray-dark\" title=\"notebook.ipynb\" id=\"2c23a4371ad3651c48a34c44792ac573-32f3c1c2ba85a153ed852a192a62d11b8d6cd9a9\" href=\"/mrbarkis/DataCamp_projects/blob/master/A%20Network%20Analysis%20of%20Game%20of%20Thrones/notebook.ipynb\">notebook.ipynb</a>\n",
    "```\n",
    "Here, the href cannot be used for downloading, because it opens the notebook in browser instead. To get the download link, we can modify the url by removing the \"/blob\" and replacing the \"github/\" with \"raw.githubusercontent/\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from local picle: localdata/urls.p\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                   title language       author  \\\n",
       "0  A Network Analysis of Game of Thrones   python  Mridul Seth   \n",
       "\n",
       "                       bio                          datacamp_url  \\\n",
       "0  Data science enthusiast  https://www.datacamp.com/projects/76   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_file = \"localdata/urls.p\"\n",
    "if not path.exists(urls_file) or update_repo_data:\n",
    "    print(\"Scraping from GitHub:\")\n",
    "    urls = []\n",
    "    dl_urls = []\n",
    "    for i, row in joined.iterrows():\n",
    "        print(f\"Url: {row.repo_url}\")\n",
    "        r = requests.get(row.repo_url)\n",
    "        r.encoding = 'utf-8'\n",
    "        page = BeautifulSoup(r.text)\n",
    "        href = page.find(\"a\", {\"title\": \"notebook.ipynb\"}).get('href')\n",
    "        url = \"https://www.github.com\" + href\n",
    "        dl_url = \"https://raw.githubusercontent.com\" + href.replace(\"/blob\", \"\")\n",
    "        urls.append(url)\n",
    "        dl_urls.append(dl_url)\n",
    "        \n",
    "    pickle.dump((urls, dl_urls), open(urls_file, \"wb\"))\n",
    "else:\n",
    "    print(f\"Loading from local picle: {urls_file}\")\n",
    "    urls, dl_urls = pickle.load(open(urls_file, \"rb\"))\n",
    "\n",
    "joined[\"notebook_url\"] = pd.Series(urls)\n",
    "joined[\"notebook_dl_url\"] = pd.Series(dl_urls)\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Define helper functions that can parse code, text, etc from the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_code(file_name):\n",
    "    \"\"\"Read notebook and separate text from code.\"\"\"\n",
    "    with open(file_name, 'r') as file:\n",
    "        j = json.load(file)\n",
    "\n",
    "    txt = \"\"\n",
    "    code = []\n",
    "    for cell in j[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"markdown\":\n",
    "            txt += BeautifulSoup(\"\".join(cell[\"source\"])).text +\"\\n\\n\"\n",
    "        elif cell[\"cell_type\"] == \"code\":\n",
    "           code.extend(cell[\"source\"])\n",
    "    \n",
    "    return txt, code\n",
    "\n",
    "\n",
    "def parse_lines(pattern, lines, suffix=\"\"):\n",
    "    \"\"\"Seach for a pattern line by line and collect the results as a list.\"\"\"\n",
    "    p = re.compile(pattern)\n",
    "    matches = []\n",
    "    for line in lines:\n",
    "        match = p.findall(line)\n",
    "            \n",
    "        if match:\n",
    "            match = [m + suffix for m in match]\n",
    "            matches.extend(match)\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an old file: ./localdata/A_Network_Analysis_of_Game_of_Thrones.ipynb\n",
      "\n",
      "## The first five lines of code are:\n",
      "# Importing modules\n",
      "import pandas as pd\n",
      "\n",
      "# Reading in datasets/book1.csv\n",
      "book1 = pd.read_csv('datasets/book1.csv')\n",
      "\n",
      "\n",
      "## The parsed methods are:\n",
      "['.read_csv()', '.head()', '.set_xticks()', '.arange()', '.set_xticklabels()', '.arange()', '.set_xlabel()', '.Graph()', '.iterrows()', '.add_edge()', '.read_csv()', '.Graph()', '.iterrows()', '.add_edge()', '.append()', '.degree_centrality()', '.degree_centrality()', '.items()', '.items()', '.degree_centrality()', '.from_records()', '.head()', '.plot()', '.set_ylabel()', '.set_title()', '.betweenness_centrality()', '.from_records()', '.fillna()', '.sort_values()', '.plot()', '.set_ylabel()', '.set_title()', '.pagerank()', '.from_records()', '.sort_values()', '.plot()', '.set_ylabel()', '.set_title()', '.pagerank()', '.betweenness_centrality()', '.degree_centrality()', '.from_records()', '.corr()', '.idxmax()']\n",
      "\n",
      "## The parsed imports are:\n",
      "['import pandas as pd', 'import networkx as nx', 'import numpy as np']\n",
      "\n",
      "##T he parsed functions are:\n",
      "['setBookAxes()', 'sorted()', 'sorted()', 'print()', 'print()', 'setBookAxes()', 'set()', 'range()', 'set()', 'list()', 'list()', 'setBookAxes()', 'set()', 'range()', 'set()', 'list()', 'list()', 'setBookAxes()', 'print()']\n",
      "\n",
      "## The parsed attributes are:\n",
      "['.csv', '.csv', '.csv', '.csv', '.csv', '.csv', '.DataFrame', '.DataFrame', '.T', '.index', '.DataFrame', '.T', '.index', '.DataFrame', '.T', '.T']\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions:\n",
    "# Load a notebook:\n",
    "row = joined.loc[0]\n",
    "file_url = row[\"notebook_dl_url\"]\n",
    "file_name = \"./localdata/\" + row[\"title\"].replace(\" \", \"_\") + \".ipynb\"\n",
    "downloadPage(file_url, file_name, overwrite=False, binary=True)\n",
    "\n",
    "# Separate the text from the code:\n",
    "txt, code = extract_text_and_code(file_name)\n",
    "\n",
    "# Test parsing using regex:\n",
    "imports = parse_lines(r\"^import.*$\", code)\n",
    "imports.extend(parse_lines(r\"^from.*$\", code))\n",
    "methods = parse_lines(r\"\\.\\w+\\(\", code,  suffix=\")\")\n",
    "functions = parse_lines(r\"(?<!\\.)\\b\\w+\\(\", code, suffix=\")\")\n",
    "attributes = parse_lines(r\"\\.\\w+\\b(?!\\()\",code)\n",
    "\n",
    "\n",
    "print(\"\\n## The first five lines of code are:\\n\" + \"\".join(code[:5]))\n",
    "\n",
    "print(\"\\n## The parsed methods are:\")\n",
    "print(methods)\n",
    "\n",
    "print(\"\\n## The parsed imports are:\")\n",
    "print(imports)\n",
    "\n",
    "print(\"\\n##T he parsed functions are:\")\n",
    "print(functions)\n",
    "\n",
    "print(\"\\n## The parsed attributes are:\")\n",
    "print(attributes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Download and parse all the notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an old file: ./localdata/A_Network_Analysis_of_Game_of_Thrones.ipynb\n",
      "Using an old file: ./localdata/A_New_Era_of_Data_Analysis_in_Baseball.ipynb\n",
      "Using an old file: ./localdata/A_Visual_History_of_Nobel_Prize_Winners.ipynb\n",
      "Using an old file: ./localdata/Analyze_Your_Runkeeper_Fitness_Data.ipynb\n",
      "Using an old file: ./localdata/Bad_passwords_and_the_NIST_guidelines.ipynb\n",
      "Using an old file: ./localdata/Book_Recommendations_from_Charles_Darwin.ipynb\n",
      "Using an old file: ./localdata/Comparing_Cosmetics_by_Ingredients.ipynb\n",
      "Using an old file: ./localdata/Disney_Movies_and_Box_Office_Success.ipynb\n",
      "Using an old file: ./localdata/Do_Left-handed_People_Really_Die_Young?.ipynb\n",
      "Using an old file: ./localdata/Dr._Semmelweis_and_the_Discovery_of_Handwashing.ipynb\n",
      "Using an old file: ./localdata/Exploring_the_Bitcoin_Cryptocurrency_Market.ipynb\n",
      "Using an old file: ./localdata/Exploring_the_Evolution_of_Linux.ipynb\n",
      "Using an old file: ./localdata/Exploring_the_History_of_Lego.ipynb\n",
      "Using an old file: ./localdata/Extract_Stock_Sentiment_from_News_Headlines.ipynb\n",
      "Using an old file: ./localdata/Find_Movie_Similarity_from_Plot_Summaries.ipynb\n",
      "Using an old file: ./localdata/Generating_Keywords_for_Google_Ads.ipynb\n",
      "Using an old file: ./localdata/Introduction_to_DataCamp_Projects.ipynb\n",
      "Using an old file: ./localdata/Introduction_to_DataCamp_Projects.ipynb\n",
      "Using an old file: ./localdata/Naïve_Bees:_Image_Loading_and_Processing.ipynb\n",
      "Using an old file: ./localdata/Naïve_Bees:_Predict_Species_from_Images.ipynb\n",
      "Using an old file: ./localdata/Predicting_Credit_Card_Approvals.ipynb\n",
      "Using an old file: ./localdata/Real-time_Insights_from_Social_Media_Data.ipynb\n",
      "Using an old file: ./localdata/Recreating_John_Snow's_Ghost_Map.ipynb\n",
      "Using an old file: ./localdata/Risk_and_Returns:_The_Sharpe_Ratio.ipynb\n",
      "Using an old file: ./localdata/TV,_Halftime_Shows,_and_the_Big_Game.ipynb\n",
      "Using an old file: ./localdata/The_Android_App_Market_on_Google_Play.ipynb\n",
      "Using an old file: ./localdata/The_GitHub_History_of_the_Scala_Language.ipynb\n",
      "Using an old file: ./localdata/The_Hottest_Topics_in_Machine_Learning.ipynb\n",
      "Using an old file: ./localdata/Up_and_Down_With_the_Kardashians.ipynb\n",
      "Using an old file: ./localdata/Who_Is_Drunk_and_When_in_Ames,_Iowa?.ipynb\n",
      "Using an old file: ./localdata/Who's_Tweeting?_Trump_or_Trudeau?.ipynb\n",
      "Using an old file: ./localdata/Word_Frequency_in_Classic_Novels.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "      <th>imports</th>\n",
       "      <th>attributes</th>\n",
       "      <th>methods</th>\n",
       "      <th>functions</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[import pandas as pd, import networkx as nx, i...</td>\n",
       "      <td>[.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...</td>\n",
       "      <td>[.read_csv(), .head(), .set_xticks(), .arange(...</td>\n",
       "      <td>[setBookAxes(), sorted(), sorted(), print(), p...</td>\n",
       "      <td>## 1. Winter is Coming. Let's load the dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[import pandas as pd, import matplotlib.pyplot...</td>\n",
       "      <td>[.pyplot, .csv, .csv, .max_columns, .str, .str...</td>\n",
       "      <td>[.read_csv(), .read_csv(), .set_option(), .tai...</td>\n",
       "      <td>[print(), print(), print(), print(), assign_x_...</td>\n",
       "      <td>## 1. The Statcast revolution\\n\\nThis is Aaron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Visual History of Nobel Prize Winners</td>\n",
       "      <td>python</td>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/441</td>\n",
       "      <td>Explore a dataset from Kaggle containing a cen...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[import pandas as pd, import seaborn as sns, i...</td>\n",
       "      <td>[.csv, .pyplot, .rcParams, .figsize, .ticker, ...</td>\n",
       "      <td>[.read_csv(), .head(), .value_counts(), .value...</td>\n",
       "      <td>[display(), len(), display(), PercentFormatter...</td>\n",
       "      <td>## 1. The most Nobel of Prizes\\n\\nThe Nobel Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "2  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                     title language         author  \\\n",
       "0    A Network Analysis of Game of Thrones   python    Mridul Seth   \n",
       "1   A New Era of Data Analysis in Baseball   python  David Venturi   \n",
       "2  A Visual History of Nobel Prize Winners   python   Rasmus Bååth   \n",
       "\n",
       "                                                 bio  \\\n",
       "0                            Data science enthusiast   \n",
       "1                     Curriculum Manager at DataCamp   \n",
       "2  Senior Data Scientist at King (Activision Bliz...   \n",
       "\n",
       "                            datacamp_url  \\\n",
       "0   https://www.datacamp.com/projects/76   \n",
       "1  https://www.datacamp.com/projects/250   \n",
       "2  https://www.datacamp.com/projects/441   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "1  Use MLB's Statcast data to compare New York Ya...   \n",
       "2  Explore a dataset from Kaggle containing a cen...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "1  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "2  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \\\n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "1  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "2  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "\n",
       "                                             imports  \\\n",
       "0  [import pandas as pd, import networkx as nx, i...   \n",
       "1  [import pandas as pd, import matplotlib.pyplot...   \n",
       "2  [import pandas as pd, import seaborn as sns, i...   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  [.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...   \n",
       "1  [.pyplot, .csv, .csv, .max_columns, .str, .str...   \n",
       "2  [.csv, .pyplot, .rcParams, .figsize, .ticker, ...   \n",
       "\n",
       "                                             methods  \\\n",
       "0  [.read_csv(), .head(), .set_xticks(), .arange(...   \n",
       "1  [.read_csv(), .read_csv(), .set_option(), .tai...   \n",
       "2  [.read_csv(), .head(), .value_counts(), .value...   \n",
       "\n",
       "                                           functions  \\\n",
       "0  [setBookAxes(), sorted(), sorted(), print(), p...   \n",
       "1  [print(), print(), print(), print(), assign_x_...   \n",
       "2  [display(), len(), display(), PercentFormatter...   \n",
       "\n",
       "                                               texts  \n",
       "0  ## 1. Winter is Coming. Let's load the dataset...  \n",
       "1  ## 1. The Statcast revolution\\n\\nThis is Aaron...  \n",
       "2  ## 1. The most Nobel of Prizes\\n\\nThe Nobel Pr...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports, attributes, methods, functions, texts = [], [], [], [], []\n",
    "\n",
    "for _, row in joined.iterrows():\n",
    "    # Load the file:\n",
    "    file_url = row[\"notebook_dl_url\"]\n",
    "    file_name = \"./localdata/\" + row[\"title\"].replace(\" \", \"_\") + \".ipynb\"\n",
    "    downloadPage(file_url, file_name, overwrite=False, binary=True)\n",
    "    \n",
    "    # Separate the text and the code:\n",
    "    txt, code = extract_text_and_code(file_name)\n",
    "    \n",
    "    # Parse code:\n",
    "    i = parse_lines(r\"^import.*$\", code)\n",
    "    i.extend(parse_lines(r\"^from.*$\", code)) # using ^(import|from) causes headache\n",
    "    m = parse_lines(r\"\\.\\w+\\(\", code,  suffix=\")\")\n",
    "    f = parse_lines(r\"(?<!\\.)\\b\\w+\\(\", code, suffix=\")\")\n",
    "    a = parse_lines(r\"\\.\\w+\\b(?!\\()\",code)\n",
    "\n",
    "    # Store results:\n",
    "    texts.append(txt)\n",
    "    imports.append(i)\n",
    "    attributes.append(a)\n",
    "    methods.append(m)\n",
    "    functions.append(f)\n",
    "\n",
    "# Add to DataFrame:\n",
    "joined[\"imports\"] = pd.Series(imports)\n",
    "joined[\"attributes\"] = pd.Series(attributes)\n",
    "joined[\"methods\"] = pd.Series(methods)\n",
    "joined[\"functions\"] = pd.Series(functions)\n",
    "joined[\"texts\"] = pd.Series(texts)\n",
    "\n",
    "joined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backup:\n",
    "    joined.to_csv(\"./data/raw_data_backup.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Analyse which words, and functions are the most descriptive\n",
    "    1) Tokenize the imports and texts, which are still sentenses\n",
    "    2) Sort the tokens using the tf-idf, or term frequency–inverse document frequency, metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Tokenize the imports and texts, which are still sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Original import statements:\n",
      "['import pandas as pd', 'import matplotlib.pyplot as plt', 'import seaborn as sns']\n",
      "\n",
      "# As a string:\n",
      "import pandas as pd import matplotlib.pyplot as plt import seaborn as sns\n",
      "\n",
      "# As a list of tokens:\n",
      "['import', 'pandas', 'as', 'pd', 'import', 'matplotlib.pyplot', 'as', 'plt', 'import', 'seaborn', 'as', 'sns']\n",
      "\n",
      "# Without stopwords:\n",
      "['pandas', 'matplotlib.pyplot', 'seaborn']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "      <th>imports</th>\n",
       "      <th>attributes</th>\n",
       "      <th>methods</th>\n",
       "      <th>functions</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[pandas, networkx, numpy]</td>\n",
       "      <td>[.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...</td>\n",
       "      <td>[.read_csv(), .head(), .set_xticks(), .arange(...</td>\n",
       "      <td>[setBookAxes(), sorted(), sorted(), print(), p...</td>\n",
       "      <td>## 1. Winter is Coming. Let's load the dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[pandas, matplotlib.pyplot, seaborn]</td>\n",
       "      <td>[.pyplot, .csv, .csv, .max_columns, .str, .str...</td>\n",
       "      <td>[.read_csv(), .read_csv(), .set_option(), .tai...</td>\n",
       "      <td>[print(), print(), print(), print(), assign_x_...</td>\n",
       "      <td>## 1. The Statcast revolution\\n\\nThis is Aaron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                    title language         author  \\\n",
       "0   A Network Analysis of Game of Thrones   python    Mridul Seth   \n",
       "1  A New Era of Data Analysis in Baseball   python  David Venturi   \n",
       "\n",
       "                              bio                           datacamp_url  \\\n",
       "0         Data science enthusiast   https://www.datacamp.com/projects/76   \n",
       "1  Curriculum Manager at DataCamp  https://www.datacamp.com/projects/250   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "1  Use MLB's Statcast data to compare New York Ya...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "1  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \\\n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "1  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "\n",
       "                                imports  \\\n",
       "0             [pandas, networkx, numpy]   \n",
       "1  [pandas, matplotlib.pyplot, seaborn]   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  [.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...   \n",
       "1  [.pyplot, .csv, .csv, .max_columns, .str, .str...   \n",
       "\n",
       "                                             methods  \\\n",
       "0  [.read_csv(), .head(), .set_xticks(), .arange(...   \n",
       "1  [.read_csv(), .read_csv(), .set_option(), .tai...   \n",
       "\n",
       "                                           functions  \\\n",
       "0  [setBookAxes(), sorted(), sorted(), print(), p...   \n",
       "1  [print(), print(), print(), print(), assign_x_...   \n",
       "\n",
       "                                               texts  \n",
       "0  ## 1. Winter is Coming. Let's load the dataset...  \n",
       "1  ## 1. The Statcast revolution\\n\\nThis is Aaron...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the import statements\n",
    "print_index = 1\n",
    "imports = list(joined.imports)\n",
    "\n",
    "print(f\"# Original import statements:\\n{imports[print_index]}\")\n",
    "imports = [\" \".join(i) for i in imports]\n",
    "\n",
    "print(f\"\\n# As a string:\\n{imports[print_index]}\")\n",
    "imports = [i.split(\" \") for i in imports]\n",
    "\n",
    "print(f\"\\n# As a list of tokens:\\n{imports[print_index]}\")\n",
    "\n",
    "stoplist = set('import as from pd np sns nx plt sm ,'.split())\n",
    "\n",
    "imports = [[token for token in tokens if token not in stoplist]\n",
    "           for tokens in imports]\n",
    "print(f\"\\n# Without stopwords:\\n{imports[print_index]}\")\n",
    "joined[\"imports\"]=pd.Series(imports)\n",
    "joined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A snippet from the the original text:\n",
      "## 1. Obtain and review raw data\n",
      "One day, my old running friend and I were chatting about our runnin\n",
      "\n",
      "# First tokens:\n",
      "['1', 'Obtain', 'and', 'review', 'raw', 'data', 'One', 'day', 'my', 'old']\n",
      "\n",
      "# Tokens to lower case:\n",
      "['1', 'obtain', 'and', 'review', 'raw', 'data', 'one', 'day', 'my', 'old']\n",
      "\n",
      "# First non-generic tokens:\n",
      "['1', 'obtain', 'review', 'raw', 'data', 'one', 'day', 'old', 'running', 'friend']\n",
      "\n",
      "# Stem the tokens:\n",
      "['1', 'obtain', 'review', 'raw', 'data', 'one', 'day', 'old', 'run', 'friend']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize texts\n",
    "texts = list(joined.texts)\n",
    "print_index = 3\n",
    "\n",
    "print(\"# A snippet from the the original text:\")\n",
    "print(texts[print_index][:100])\n",
    "\n",
    "print(\"\\n# First tokens:\")\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(pattern='\\w+')\n",
    "all_tokens = [tokenizer.tokenize(text=text) for text in texts]\n",
    "print(all_tokens[print_index][:10])\n",
    "\n",
    "print(\"\\n# Tokens to lower case:\")\n",
    "all_tokens = [[token.lower() for token in tokens]\n",
    "              for tokens in all_tokens]\n",
    "print(all_tokens[print_index][:10])\n",
    "\n",
    "print(\"\\n# First non-generic tokens:\")\n",
    "#nltk.download('stopwords')\n",
    "sw = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = [[token for token in tokens if token not in sw]\n",
    "              for tokens in all_tokens]\n",
    "print(all_tokens[print_index][:10])\n",
    "\n",
    "print(\"\\n# Stem the tokens:\")\n",
    "porter = nltk.stem.PorterStemmer()\n",
    "all_tokens = [[porter.stem(token) for token in tokens]\n",
    "             for tokens in all_tokens]\n",
    "print(all_tokens[print_index][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "      <th>imports</th>\n",
       "      <th>attributes</th>\n",
       "      <th>methods</th>\n",
       "      <th>functions</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[pandas, networkx, numpy]</td>\n",
       "      <td>[.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...</td>\n",
       "      <td>[.read_csv(), .head(), .set_xticks(), .arange(...</td>\n",
       "      <td>[setBookAxes(), sorted(), sorted(), print(), p...</td>\n",
       "      <td>[1, winter, come, let, load, dataset, asap, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[pandas, matplotlib.pyplot, seaborn]</td>\n",
       "      <td>[.pyplot, .csv, .csv, .max_columns, .str, .str...</td>\n",
       "      <td>[.read_csv(), .read_csv(), .set_option(), .tai...</td>\n",
       "      <td>[print(), print(), print(), print(), assign_x_...</td>\n",
       "      <td>[1, statcast, revolut, aaron, judg, judg, one,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                    title language         author  \\\n",
       "0   A Network Analysis of Game of Thrones   python    Mridul Seth   \n",
       "1  A New Era of Data Analysis in Baseball   python  David Venturi   \n",
       "\n",
       "                              bio                           datacamp_url  \\\n",
       "0         Data science enthusiast   https://www.datacamp.com/projects/76   \n",
       "1  Curriculum Manager at DataCamp  https://www.datacamp.com/projects/250   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "1  Use MLB's Statcast data to compare New York Ya...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "1  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \\\n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "1  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "\n",
       "                                imports  \\\n",
       "0             [pandas, networkx, numpy]   \n",
       "1  [pandas, matplotlib.pyplot, seaborn]   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  [.csv, .csv, .csv, .csv, .csv, .csv, .DataFram...   \n",
       "1  [.pyplot, .csv, .csv, .max_columns, .str, .str...   \n",
       "\n",
       "                                             methods  \\\n",
       "0  [.read_csv(), .head(), .set_xticks(), .arange(...   \n",
       "1  [.read_csv(), .read_csv(), .set_option(), .tai...   \n",
       "\n",
       "                                           functions  \\\n",
       "0  [setBookAxes(), sorted(), sorted(), print(), p...   \n",
       "1  [print(), print(), print(), print(), assign_x_...   \n",
       "\n",
       "                                               texts  \n",
       "0  [1, winter, come, let, load, dataset, asap, he...  \n",
       "1  [1, statcast, revolut, aaron, judg, judg, one,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.texts = pd.Series(all_tokens)\n",
    "joined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Sort the tokens using the tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_frequency(all_tokens):\n",
    "    \"\"\"Sort tokens both by occurance\"\"\"\n",
    "    dictionary = corpora.Dictionary(all_tokens)\n",
    "    bows = [dictionary.doc2bow(tokens) for tokens in all_tokens]\n",
    "    by_frequency = [[dictionary[token[0]] \n",
    "                           for token \n",
    "                            in sorted(bow, key=lambda x: x[1], reverse=True)]\n",
    "                            for bow in bows]\n",
    "    return by_frequency\n",
    "\n",
    "def sort_by_tfidf(all_tokens):\n",
    "    \"\"\"Sort tokens both by tf-idf\"\"\"\n",
    "    dictionary = corpora.Dictionary(all_tokens)\n",
    "    bows = [dictionary.doc2bow(tokens) for tokens in all_tokens]\n",
    "    model = TfidfModel(bows)\n",
    "    \n",
    "    by_tfidf=[]\n",
    "    for bow in bows:\n",
    "        tfidf = model[bow]\n",
    "        by_tfidf.append(\n",
    "            [dictionary[token[0]] for token \n",
    "             in sorted(tfidf, key=lambda x: x[1], reverse=True)]\n",
    "        )\n",
    "   \n",
    "    return by_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "      <th>imports</th>\n",
       "      <th>attributes</th>\n",
       "      <th>methods</th>\n",
       "      <th>functions</th>\n",
       "      <th>texts</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[networkx, numpy, pandas]</td>\n",
       "      <td>[.DataFrame, .T, .index, .csv]</td>\n",
       "      <td>[.degree_centrality(), .from_records(), .Graph...</td>\n",
       "      <td>[setBookAxes(), list(), set(), sorted(), range...</td>\n",
       "      <td>[1, winter, come, let, load, dataset, asap, he...</td>\n",
       "      <td>[book, network, central, charact, throne, fift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[seaborn, matplotlib.pyplot, pandas]</td>\n",
       "      <td>[.zone, .loc, .max_columns, .str, .pyplot, .csv]</td>\n",
       "      <td>[.set_visible(), .gca(), .set_title(), .apply(...</td>\n",
       "      <td>[assign_x_coord(), assign_y_coord(), print()]</td>\n",
       "      <td>[1, statcast, revolut, aaron, judg, judg, one,...</td>\n",
       "      <td>[pitch, home, stanton, statcast, judg, ball, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Visual History of Nobel Prize Winners</td>\n",
       "      <td>python</td>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/441</td>\n",
       "      <td>Explore a dataset from Kaggle containing a cen...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[PercentFormatter, matplotlib.ticker, seaborn,...</td>\n",
       "      <td>[.ticker, .yaxis, .figsize, .rcParams, .year, ...</td>\n",
       "      <td>[.nsmallest(), .lineplot(), .lmplot(), .set_ma...</td>\n",
       "      <td>[PercentFormatter(), display(), len()]</td>\n",
       "      <td>[1, nobel, prize, nobel, prize, perhap, world,...</td>\n",
       "      <td>[prize, winner, nobel, 1901, imbal, peac, chem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "2  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                     title language         author  \\\n",
       "0    A Network Analysis of Game of Thrones   python    Mridul Seth   \n",
       "1   A New Era of Data Analysis in Baseball   python  David Venturi   \n",
       "2  A Visual History of Nobel Prize Winners   python   Rasmus Bååth   \n",
       "\n",
       "                                                 bio  \\\n",
       "0                            Data science enthusiast   \n",
       "1                     Curriculum Manager at DataCamp   \n",
       "2  Senior Data Scientist at King (Activision Bliz...   \n",
       "\n",
       "                            datacamp_url  \\\n",
       "0   https://www.datacamp.com/projects/76   \n",
       "1  https://www.datacamp.com/projects/250   \n",
       "2  https://www.datacamp.com/projects/441   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "1  Use MLB's Statcast data to compare New York Ya...   \n",
       "2  Explore a dataset from Kaggle containing a cen...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "1  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "2  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \\\n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "1  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "2  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "\n",
       "                                             imports  \\\n",
       "0                          [networkx, numpy, pandas]   \n",
       "1               [seaborn, matplotlib.pyplot, pandas]   \n",
       "2  [PercentFormatter, matplotlib.ticker, seaborn,...   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                     [.DataFrame, .T, .index, .csv]   \n",
       "1   [.zone, .loc, .max_columns, .str, .pyplot, .csv]   \n",
       "2  [.ticker, .yaxis, .figsize, .rcParams, .year, ...   \n",
       "\n",
       "                                             methods  \\\n",
       "0  [.degree_centrality(), .from_records(), .Graph...   \n",
       "1  [.set_visible(), .gca(), .set_title(), .apply(...   \n",
       "2  [.nsmallest(), .lineplot(), .lmplot(), .set_ma...   \n",
       "\n",
       "                                           functions  \\\n",
       "0  [setBookAxes(), list(), set(), sorted(), range...   \n",
       "1      [assign_x_coord(), assign_y_coord(), print()]   \n",
       "2             [PercentFormatter(), display(), len()]   \n",
       "\n",
       "                                               texts  \\\n",
       "0  [1, winter, come, let, load, dataset, asap, he...   \n",
       "1  [1, statcast, revolut, aaron, judg, judg, one,...   \n",
       "2  [1, nobel, prize, nobel, prize, perhap, world,...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [book, network, central, charact, throne, fift...  \n",
       "1  [pitch, home, stanton, statcast, judg, ball, v...  \n",
       "2  [prize, winner, nobel, 1901, imbal, peac, chem...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort all the tokens based on the tfidf score\n",
    "columns = [\"functions\", \"methods\", \"attributes\", \"imports\"]\n",
    "for col in columns:\n",
    "    tokens = list(joined[col])\n",
    "    joined[col] = pd.Series(sort_by_tfidf(tokens))\n",
    "\n",
    "joined[\"keywords\"] = pd.Series([keys[:20] for keys\n",
    "                                in sort_by_tfidf(joined.texts)])\n",
    "\n",
    "joined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exract long descriptions from DataCamp\n",
    "The project pages at \"datacamp_url\" look like this\n",
    "![project wreppers](img/project_description.png \"descriptions on datacamp_url\")\n",
    "The code looks like\n",
    "```html\n",
    "<h4>Project Description</h4>\n",
    "<div>\n",
    "    <p>Description ...</p>\n",
    "    <p>Description ...</p>\n",
    "    <p>Description ...</p>\n",
    "</div>\n",
    "```\n",
    "we can search for the tag after the h4 heading tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an old file: ./localdata/A_Network_Analysis_of_Game_of_Thrones.html\n",
      "Using an old file: ./localdata/A_New_Era_of_Data_Analysis_in_Baseball.html\n",
      "Using an old file: ./localdata/A_Visual_History_of_Nobel_Prize_Winners.html\n",
      "Using an old file: ./localdata/Analyze_Your_Runkeeper_Fitness_Data.html\n",
      "Using an old file: ./localdata/Bad_passwords_and_the_NIST_guidelines.html\n",
      "Using an old file: ./localdata/Book_Recommendations_from_Charles_Darwin.html\n",
      "Using an old file: ./localdata/Comparing_Cosmetics_by_Ingredients.html\n",
      "Using an old file: ./localdata/Disney_Movies_and_Box_Office_Success.html\n",
      "Using an old file: ./localdata/Do_Left-handed_People_Really_Die_Young?.html\n",
      "Using an old file: ./localdata/Dr._Semmelweis_and_the_Discovery_of_Handwashing.html\n",
      "Using an old file: ./localdata/Exploring_the_Bitcoin_Cryptocurrency_Market.html\n",
      "Using an old file: ./localdata/Exploring_the_Evolution_of_Linux.html\n",
      "Using an old file: ./localdata/Exploring_the_History_of_Lego.html\n",
      "Using an old file: ./localdata/Extract_Stock_Sentiment_from_News_Headlines.html\n",
      "Using an old file: ./localdata/Find_Movie_Similarity_from_Plot_Summaries.html\n",
      "Using an old file: ./localdata/Generating_Keywords_for_Google_Ads.html\n",
      "Using an old file: ./localdata/Introduction_to_DataCamp_Projects.html\n",
      "Using an old file: ./localdata/Introduction_to_DataCamp_Projects.html\n",
      "Using an old file: ./localdata/Naïve_Bees:_Image_Loading_and_Processing.html\n",
      "Using an old file: ./localdata/Naïve_Bees:_Predict_Species_from_Images.html\n",
      "Using an old file: ./localdata/Predicting_Credit_Card_Approvals.html\n",
      "Using an old file: ./localdata/Real-time_Insights_from_Social_Media_Data.html\n",
      "Using an old file: ./localdata/Recreating_John_Snow's_Ghost_Map.html\n",
      "Using an old file: ./localdata/Risk_and_Returns:_The_Sharpe_Ratio.html\n",
      "Using an old file: ./localdata/TV,_Halftime_Shows,_and_the_Big_Game.html\n",
      "Using an old file: ./localdata/The_Android_App_Market_on_Google_Play.html\n",
      "Using an old file: ./localdata/The_GitHub_History_of_the_Scala_Language.html\n",
      "Using an old file: ./localdata/The_Hottest_Topics_in_Machine_Learning.html\n",
      "Using an old file: ./localdata/Up_and_Down_With_the_Kardashians.html\n",
      "Using an old file: ./localdata/Who_Is_Drunk_and_When_in_Ames,_Iowa?.html\n",
      "Using an old file: ./localdata/Who's_Tweeting?_Trump_or_Trudeau?.html\n",
      "Using an old file: ./localdata/Word_Frequency_in_Classic_Novels.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>author</th>\n",
       "      <th>bio</th>\n",
       "      <th>datacamp_url</th>\n",
       "      <th>description</th>\n",
       "      <th>notebook_url</th>\n",
       "      <th>notebook_dl_url</th>\n",
       "      <th>imports</th>\n",
       "      <th>attributes</th>\n",
       "      <th>methods</th>\n",
       "      <th>functions</th>\n",
       "      <th>texts</th>\n",
       "      <th>keywords</th>\n",
       "      <th>long_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Network Analysis of Game of Thrones</td>\n",
       "      <td>python</td>\n",
       "      <td>Mridul Seth</td>\n",
       "      <td>Data science enthusiast</td>\n",
       "      <td>https://www.datacamp.com/projects/76</td>\n",
       "      <td>Analyze the network of characters in Game of T...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[networkx, numpy, pandas]</td>\n",
       "      <td>[.DataFrame, .T, .index, .csv]</td>\n",
       "      <td>[.degree_centrality(), .from_records(), .Graph...</td>\n",
       "      <td>[setBookAxes(), list(), set(), sorted(), range...</td>\n",
       "      <td>[1, winter, come, let, load, dataset, asap, he...</td>\n",
       "      <td>[book, network, central, charact, throne, fift...</td>\n",
       "      <td>&lt;div&gt;\\n &lt;p&gt;\\n  Jon Snow, Daenerys Targaryen, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A New Era of Data Analysis in Baseball</td>\n",
       "      <td>python</td>\n",
       "      <td>David Venturi</td>\n",
       "      <td>Curriculum Manager at DataCamp</td>\n",
       "      <td>https://www.datacamp.com/projects/250</td>\n",
       "      <td>Use MLB's Statcast data to compare New York Ya...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[seaborn, matplotlib.pyplot, pandas]</td>\n",
       "      <td>[.zone, .loc, .max_columns, .str, .pyplot, .csv]</td>\n",
       "      <td>[.set_visible(), .gca(), .set_title(), .apply(...</td>\n",
       "      <td>[assign_x_coord(), assign_y_coord(), print()]</td>\n",
       "      <td>[1, statcast, revolut, aaron, judg, judg, one,...</td>\n",
       "      <td>[pitch, home, stanton, statcast, judg, ball, v...</td>\n",
       "      <td>&lt;div&gt;\\n &lt;p&gt;\\n  There's a new era of data analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>A Visual History of Nobel Prize Winners</td>\n",
       "      <td>python</td>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/441</td>\n",
       "      <td>Explore a dataset from Kaggle containing a cen...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[PercentFormatter, matplotlib.ticker, seaborn,...</td>\n",
       "      <td>[.ticker, .yaxis, .figsize, .rcParams, .year, ...</td>\n",
       "      <td>[.nsmallest(), .lineplot(), .lmplot(), .set_ma...</td>\n",
       "      <td>[PercentFormatter(), display(), len()]</td>\n",
       "      <td>[1, nobel, prize, nobel, prize, perhap, world,...</td>\n",
       "      <td>[prize, winner, nobel, 1901, imbal, peac, chem...</td>\n",
       "      <td>&lt;div&gt;\\n &lt;p&gt;\\n  The Nobel Prize is perhaps the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>Analyze Your Runkeeper Fitness Data</td>\n",
       "      <td>python</td>\n",
       "      <td>Andrii Pavlenko</td>\n",
       "      <td>Project Instructor</td>\n",
       "      <td>https://www.datacamp.com/projects/727</td>\n",
       "      <td>Import, clean, and analyze seven years worth o...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[statsmodels.api, warnings, matplotlib.pyplot,...</td>\n",
       "      <td>[.5, .api, .figure, .observed, .trend, .tsa, ....</td>\n",
       "      <td>[.resample(), .set(), .axhspan(), .mean(), .fi...</td>\n",
       "      <td>[display(), int(), range(), print(), len()]</td>\n",
       "      <td>[1, obtain, review, raw, data, one, day, old, ...</td>\n",
       "      <td>[km, run, heart, train, miss, shoe, distanc, a...</td>\n",
       "      <td>&lt;div&gt;\\n &lt;p&gt;\\n  With the explosion in fitness t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/mrbarkis/DataCamp_projects/...</td>\n",
       "      <td>Bad passwords and the NIST guidelines</td>\n",
       "      <td>python</td>\n",
       "      <td>Rasmus Bååth</td>\n",
       "      <td>Senior Data Scientist at King (Activision Bliz...</td>\n",
       "      <td>https://www.datacamp.com/projects/141</td>\n",
       "      <td>Check what passwords fail to conform to the Na...</td>\n",
       "      <td>https://www.github.com/mrbarkis/DataCamp_proje...</td>\n",
       "      <td>https://raw.githubusercontent.com/mrbarkis/Dat...</td>\n",
       "      <td>[pandas]</td>\n",
       "      <td>[.str, .txt, .csv]</td>\n",
       "      <td>[.extract(), .sum(), .isin(), .any(), .len(), ...</td>\n",
       "      <td>[print(), len()]</td>\n",
       "      <td>[1, nist, special, public, 800, 63b, 50, year,...</td>\n",
       "      <td>[password, nist, user, secret, 63b, flag, repe...</td>\n",
       "      <td>&lt;div&gt;\\n &lt;p&gt;\\n  Almost every web service you jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "1  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "2  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "3  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "4  https://github.com/mrbarkis/DataCamp_projects/...   \n",
       "\n",
       "                                     title language           author  \\\n",
       "0    A Network Analysis of Game of Thrones   python      Mridul Seth   \n",
       "1   A New Era of Data Analysis in Baseball   python    David Venturi   \n",
       "2  A Visual History of Nobel Prize Winners   python     Rasmus Bååth   \n",
       "3      Analyze Your Runkeeper Fitness Data   python  Andrii Pavlenko   \n",
       "4    Bad passwords and the NIST guidelines   python     Rasmus Bååth   \n",
       "\n",
       "                                                 bio  \\\n",
       "0                            Data science enthusiast   \n",
       "1                     Curriculum Manager at DataCamp   \n",
       "2  Senior Data Scientist at King (Activision Bliz...   \n",
       "3                                 Project Instructor   \n",
       "4  Senior Data Scientist at King (Activision Bliz...   \n",
       "\n",
       "                            datacamp_url  \\\n",
       "0   https://www.datacamp.com/projects/76   \n",
       "1  https://www.datacamp.com/projects/250   \n",
       "2  https://www.datacamp.com/projects/441   \n",
       "3  https://www.datacamp.com/projects/727   \n",
       "4  https://www.datacamp.com/projects/141   \n",
       "\n",
       "                                         description  \\\n",
       "0  Analyze the network of characters in Game of T...   \n",
       "1  Use MLB's Statcast data to compare New York Ya...   \n",
       "2  Explore a dataset from Kaggle containing a cen...   \n",
       "3  Import, clean, and analyze seven years worth o...   \n",
       "4  Check what passwords fail to conform to the Na...   \n",
       "\n",
       "                                        notebook_url  \\\n",
       "0  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "1  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "2  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "3  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "4  https://www.github.com/mrbarkis/DataCamp_proje...   \n",
       "\n",
       "                                     notebook_dl_url  \\\n",
       "0  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "1  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "2  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "3  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "4  https://raw.githubusercontent.com/mrbarkis/Dat...   \n",
       "\n",
       "                                             imports  \\\n",
       "0                          [networkx, numpy, pandas]   \n",
       "1               [seaborn, matplotlib.pyplot, pandas]   \n",
       "2  [PercentFormatter, matplotlib.ticker, seaborn,...   \n",
       "3  [statsmodels.api, warnings, matplotlib.pyplot,...   \n",
       "4                                           [pandas]   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                     [.DataFrame, .T, .index, .csv]   \n",
       "1   [.zone, .loc, .max_columns, .str, .pyplot, .csv]   \n",
       "2  [.ticker, .yaxis, .figsize, .rcParams, .year, ...   \n",
       "3  [.5, .api, .figure, .observed, .trend, .tsa, ....   \n",
       "4                                 [.str, .txt, .csv]   \n",
       "\n",
       "                                             methods  \\\n",
       "0  [.degree_centrality(), .from_records(), .Graph...   \n",
       "1  [.set_visible(), .gca(), .set_title(), .apply(...   \n",
       "2  [.nsmallest(), .lineplot(), .lmplot(), .set_ma...   \n",
       "3  [.resample(), .set(), .axhspan(), .mean(), .fi...   \n",
       "4  [.extract(), .sum(), .isin(), .any(), .len(), ...   \n",
       "\n",
       "                                           functions  \\\n",
       "0  [setBookAxes(), list(), set(), sorted(), range...   \n",
       "1      [assign_x_coord(), assign_y_coord(), print()]   \n",
       "2             [PercentFormatter(), display(), len()]   \n",
       "3        [display(), int(), range(), print(), len()]   \n",
       "4                                   [print(), len()]   \n",
       "\n",
       "                                               texts  \\\n",
       "0  [1, winter, come, let, load, dataset, asap, he...   \n",
       "1  [1, statcast, revolut, aaron, judg, judg, one,...   \n",
       "2  [1, nobel, prize, nobel, prize, perhap, world,...   \n",
       "3  [1, obtain, review, raw, data, one, day, old, ...   \n",
       "4  [1, nist, special, public, 800, 63b, 50, year,...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [book, network, central, charact, throne, fift...   \n",
       "1  [pitch, home, stanton, statcast, judg, ball, v...   \n",
       "2  [prize, winner, nobel, 1901, imbal, peac, chem...   \n",
       "3  [km, run, heart, train, miss, shoe, distanc, a...   \n",
       "4  [password, nist, user, secret, 63b, flag, repe...   \n",
       "\n",
       "                                    long_description  \n",
       "0  <div>\\n <p>\\n  Jon Snow, Daenerys Targaryen, o...  \n",
       "1  <div>\\n <p>\\n  There's a new era of data analy...  \n",
       "2  <div>\\n <p>\\n  The Nobel Prize is perhaps the ...  \n",
       "3  <div>\\n <p>\\n  With the explosion in fitness t...  \n",
       "4  <div>\\n <p>\\n  Almost every web service you jo...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts = []\n",
    "for _, row in joined.iterrows():\n",
    "    url = row[\"datacamp_url\"]\n",
    "    file_name = \"./localdata/\" + row[\"title\"].replace(\" \", \"_\") + \".html\"\n",
    "    downloadPage(url, file_name, overwrite=False)\n",
    "    \n",
    "    with open(file_name, 'r') as html_file:\n",
    "        html = BeautifulSoup(html_file)\n",
    "    txts.append(html.find('h4').find_next().prettify())\n",
    "\n",
    "joined[\"long_description\"] = pd.Series(txts)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Generate markdown entries\n",
    "\n",
    "Let's define a function that outputs the following text:\n",
    "\n",
    "## [Title of project](https://www.datacamp.com/projects/76 \"To repo url\")\n",
    "\n",
    "Description of the project. Description of the project. Description of the project. Description of the project. Description of the project. Description of the project. Description of the project. Description of the project. Description of the project.\n",
    "\n",
    "[Original source](https://www.datacamp.com/projects/76 \"To datacamp url\") by John Doe, Data science enthusiast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"# My completed DataCamp projects\n",
    "The below descriptions have been scraped from\n",
    "[DataCamp projects page](https://www.datacamp.com/projects).\n",
    "The keywords, imports, methods, functions, and attributes, in turn, have been scraped from the notebooks themselves,\n",
    "and sorted using the tf-idf, i.e. term frequency–inverse document frequency, metric. \"\"\"\n",
    "for i, r in joined.iterrows():\n",
    "    title, author, description, long, repo_url, url, bio = (r.title,\n",
    "                                                      r.author,\n",
    "                                                      r.description,\n",
    "                                                      r.long_description,\n",
    "                                                      r.notebook_url,\n",
    "                                                      r.datacamp_url,\n",
    "                                                      r.bio)\n",
    "    heading = f\"\\n## [{title}]({repo_url})\"\n",
    "    info = f\"\\n{long} \\n\"\n",
    "    source = f\"\\n[Original project]({url}) by {author}, {bio}\\n\"\n",
    "\n",
    "    \n",
    "    keywords = \" \".join(r.keywords)  \n",
    "    imports = \" \".join(r.imports)\n",
    "    methods = \" \".join(r.methods)\n",
    "    functions = \" \".join(r.functions)\n",
    "    attributes = \" \".join(r.attributes)\n",
    "    \n",
    "    \n",
    "    table = \"\\n\\n| Keywords | Imports | Methods | Functions | Attributes/Extensions|\"\n",
    "    table += \"\\n| --- |--- | --- | --- | --- |\"\n",
    "    table += \"\\n|\" + keywords\n",
    "    table += \"|\" + imports\n",
    "    table += \"|\" + methods\n",
    "    table += \"|\" + functions\n",
    "    table += \"|\" + attributes\n",
    "    table += \"|\\n\\n\"\n",
    "    \n",
    "    text += heading  + info + table + source\n",
    "    \n",
    "\n",
    "with open(\"project_list.md\", 'w') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup the joined DataFrame\n",
    "if backup:\n",
    "    joined.to_csv(\"./data/data_backup.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
